# 2021-Number_of_Diners_Prediction / 구내식당 식수인원 예측 경진대회 (DACON)

일정 : 2021.06.03 ~ 2021.07.23

## 대회 설명 / 링크

[https://dacon.io/competitions/official/235743/overview/description](https://dacon.io/competitions/official/235743/overview/description)

## 대회 진행 과정

나와 2명의 서울시립대학교 컴퓨터 과학부 학생들이 한 팀을 이루어 진행했다. 나를 포함해서 다들 AI대회가 처음이었기 때문에, 처음에는 맨땅에 헤딩하는 느낌이었다. 솔직히 말하자면, 끝날때까지 맨땅에 헤딩하는 기분이었다. EDA와 전처리, 그리고 모델링까지 전부 다 제대로 알고 시작한 것이 아니기 때문에 중간중간 공부를 열심히 해야했다. 고생한만큼 많은 것을 얻어갈 수 있는 대회였던 것 같다. 특히 Pandas나 Numpy에 대해 공부하고 이를 활용할 수 있게 되었다는 점에서 큰 성장을 이루었다고 할 수 있을 것 같다(원래는 아무것도 몰랐다...). 

이번 대회가 끝나고 지난 학기에 Titanic 노트북 필사했던 것을 보았더니 코드가 이해가 가기 시작했다. 

ML 공부를 하면서 많은 즐거움을 느낄 수 있었고, 그 어느 대회보다 열심히 준비했다. 

## 대회 결과

다들 실력이 아무래도 부족하다보다 결과가 좋지 못했다. 

## Code Process

### → 1. 전처리

#1. 요일을 숫자로 변환했다. 

이유는 두가지였다. 첫째, 월요일에서 금요일으로 갈수록 중식과 석식을 먹는 비율(중식참여율, 석식참여율)이 작아졌다. 둘째, 자연어로 입력을 하는 것보다 컴퓨터 언어인 숫자로 입력을 하는게 연산이 더 빠를 것 같다는 생각을 했다.

#2. 공휴일 데이터 고려를 했다. 

공휴일 전날은 직원들이 회사 내에서 밥을 많이 안먹을 것이라 예상했다. 그러나 실제로 데이터를 확인해보니 공휴일이 공휴일 전날의 중석식 참여율에 영향을 미치지 못했다. 그런데 공휴일 다음 날의 데이터를 살펴보니, 석식 참여율이 다른 날들보다 낮은 것을 파악할 수 있었다. 그래서 <설날 다음날> 칼럼을 만들어서, 설날 다음날이면 1, 그렇기 않을 경우에는 0을 입력했다. 설날만 고려한 이유는 test set에 있는 데이터는 1월부터 4월까지밖에 없기 때문이다.

#3. 수요일 자기계발의 날 고려를 했다.

데이터를 제공한 회사에서는 매달 마지막 주 수요일을 '자기계발의 날'으로 지정했다. 이 날은, 모든 회사원들이 조기퇴근하는 날이기 때문에 석식참여율은 0인 날이다. 이를 반영하기 위해 <자기계발의 날> 칼럼을 만들어서 자기계발의 날이면 1, 아닐 경우에는 0을 입력했다. 

그런데 model을 학습시키고 test set으로 결과를 받아보면 자기계발의 날 석식참여율이 0이 아닌 것을 확인할 수 있었다. 새로운 칼럼을 만드는 것만으로는 0을 만들 수 없는 것을 깨달았고, 이를 개선하기 위한 방안들을 생각해보려 했지만 딱히 대체 방안이 떠오르지 않았다. 그래서 이후에는 아예 중식 데이터셋과 석식 데이터셋을 따로 만들어서 석식 데이터셋에서는 <자기계발의 날> 칼럼이 1인 row를 모두 삭제하기도 했다. 이렇게 한 이유는 자기계발의 날이라는 특이한 소수의 데이터로 인해 예측률이 떨어졌을 것이라 생각했기 때문이다. 그런데 이 방안으로도 성적이 좋지는 못했다.

#4. 중석식을 분기별로 mapping

전체 데이터를 월별로 평균을 내어 중식과 석식의 참여율을 기준으로 3달을 한 개의 그룹으로 mapping했다. 중식의 경우, (2,3,1 / 4,10,8 / 9,5,6 / 7,12,11) 이렇게 mapping을 했으며, 석식의 경우, (3,2,4 / 8,10,6 / 5,9,7 / 11,1,12)로 mapping을 했다. 그러나 성적은 좋지 못했다.

#5. 중석식을 참여도에 따라 Ranking

#4에서 그룹화를 했을 때 성적이 잘 나오지 않아 그룹화하지 말고 개별적으로 순위를 매겨보기로 했다. 그러나 이 또한 성적이 좋지는 못했다.

## → 2. 모델링

#1. XGBoost

GridSearch로 최적의 파라미터를 찾았다. 

고려한 파라미터는 :

learning_rate, boosting_type, num_iteration, max_depth

#2. Bagging

고려한 파라미터는 :

n_estimators, max_samples, bootstrap, n_jobs, oob_score

#3. LGBM

#4. FBProphet

이 모델은 시계열 모델인데, 시계열 모델을 사용한 이유는 자기계발의 날을 고려하기 위해서이다. 매달 마지막 수요일이라는 주기성을 고려하기 위해 시계열 모델을 사용했다.

## 코드 비교

### → Private 3등 코드 분석

#1. 메뉴 고려

우리 팀은 자연어 처리를 할 줄 아는 사람이 없어서 메뉴 처리를 못했다. 그러나 이 팀은 메뉴를 고려했다. 그러나 메뉴의 모든 음식을 고려한 것이 아니라 밥, 국, 그리고 메인 메뉴(첫 번째 메뉴)만 고려했다. 메뉴의 수를 제한해줌으로써 의미없는(반복되지 않는) 메뉴들을 제거해주었다.

#2. 일(day), 밥, 국, 메인 메뉴를 인코딩

이 팀은 <<astype("category")>>로 범주형 자료로 변환시켰다. 

여기에서 <<"category">>는 데이터 프레임 칼럼에서 특정한 형태의 데이터가 반복될 때 사용된다. 예를 들어 성별 칼럼에서 남자와 여자만 반복되는 것과 같이 특정 구간에서 데이터가 반복될 때 사용한다. 

이렇게 범주형 자료로 변환시키면 반복되는 데이터의 사이즈가 줄어서 메모리 사용량이 줄어들고, 데이터 처리 속도가 빨라진다. 

##categorical 객체에 대한 추가 설명

categorical 객체는 categories와 codes의 속성을 가진다. 

```python
fruit.cat.categories
--> index['apple', 'orange'] #어떤 value가 있는지 보여준다.
fruit.cat.codes
--> array([0, 1, 1, 0, 0]) #인코딩 됨.
#categorical 객체에 바로 categories 또는 codes 사용하면 에러가 뜬다. 그래서 중간에 cat 사용해야한다. 
```

#3. 현재 인원수를 계산하는 방법에서의 차이

현재 회사에 있는 인원수를 계산할 때 본사정원수 - (본사휴가자수 + 본사출장자수 + 본사시간외근무명령서승인건수)를 했다.

#4 저녁 데이터셋에서 메뉴가 없는 날을 제거했다.

우리 팀은 메뉴가 없는 날에 대한 칼럼을 따로 만들어보기도 했는데, 이 팀은 아예 제거했다. 자기계발의 날이 나름 의미있는 데이터라고 생각했는데, 우리 팀의 결과와 이 팀의 결과를 생각해보면 그다지 의미있는 데이터가 되지 못했음을 알 수 있다.

#5. 모델링에서 K-fold 교차검증

K-fold 교차검증이란, k개의 fold를 만들어서 진행하는 교차검증이다. 총 데이터 갯수가 작은 데이터셋에 대해 정확도 향상이 가능하다. Underfitting을 방지해준다.

#6. 모델링에서 XgBoost Regressor을 사용함. 

GridSearch 사용해서 hyperparameter max_depth, n_estimator, colsample_bytree, colsample_bylevel을 찾았다.

#7. 점심 데이터셋과 저녁 데이터셋으로 구분했다. 

이는 앞에 #3에서 저녁 식수인원이 0일 경우 제외해서 그런 것 같다.

### → other teams

다른 팀들이 한 것을 보면서 느꼈던 것은,

#1. 데이터의 중요성

특히 정형 대회에서는 더 중요하다고 느꼈다. 주어진 데이터를 어떻게 활용할 것인지, 그리고 추가적으로 어떤 데이터를 사용할 것인지 결정하는 것이 결과에 상당히 중요한 영향을 미친다고 생각했다. 어떤 팀은 날씨 데이터와 코로나 데이터, 그리고 LH와 관련된 기사 자료도 데이터로 사용했다. 

#2. 절차의 중요성

여러 팀들의 대회 코드를 보면서 절차를 잘 지켰다는 생각이 들었다. 그들은 가정 - 가정에 근거하여 데이터 활용 - 모델링 - 확인 - 가정의 추가 / 틀린 가정 수정

이러한 방식으로 진행했다. 

#3. 노력/끈기의 중요성  

다른 팀들이 외부 데이터를 찾는 것은 결코 쉬운 일이 아니었을 것임을 알고 있다. 메뉴를 고려하는 것도 쉬운 일이 아니었을 수 있다. 

나는 이번 대회에서 나와 팀에 대해 제일 실망했던 부분이 끝날 때까지 끝난 것이 아님에도 미리 종료를 선언했다는 점이다. 우리는 어떻게 해서든 메뉴를 고려했어야했다. 제공하는 데이터를 아예 무시해버리는 일은 하지 말았어야했다. 우리가 메뉴 데이터를 고려하지 않은 이유는 다른 팀들이 작성한 글들에서 메뉴의 영향은 크게 없었다는 글을 발견했기 때문이다. 그러나 나는 우리가 직접 우리의 눈으로 정말 그 어떠한 영향도 없는지 확인해봐야 했다고 생각한다.  또한, 외부 데이터를 가져오기 위해 더 노력해야했다. 마지막으로, 우리는 더 다양한 모델들을 공부해보고 이를 적용해보려 시도했어야 했다. 

다음 대회에서부터는 실패할 가능성이 크더라도 무조건 시도해봐야겠다는 생각을 했다.
